{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "#loading data\n",
    "data = pd.read_csv(\"movie_metadata.csv\")\n",
    "\n",
    "data.shape\n",
    "data.info()\n",
    "\n",
    "#Summary of missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "#replacing NaN in Numeric variables by mean value\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "#replacing NaN in character variables by mode value\n",
    "for column in data[['color', 'language', 'country', 'content_rating']]:\n",
    "    mode = data[column].mode()\n",
    "    data[column] = data[column].fillna(mode)\n",
    "\n",
    "#dropping remaining records having NaN\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "\n",
    "#Summary of missing values\n",
    "data.isnull().sum()\n",
    "# data.info()\n",
    "\n",
    "\n",
    "\n",
    "## Data Exploration and Visualization\n",
    "\n",
    "pd.DataFrame.hist(data, figsize = [15,15]);\n",
    "\n",
    "\n",
    "#histogram of imdb scores\n",
    "data['imdb_score'].diff().hist()\n",
    "plt.title(\"imdb_score\")\n",
    "plt.show()\n",
    "\n",
    "#boxplot and scatter plots\n",
    "meanpointprops = dict(marker = 'D', markeredgecolor = 'black',\n",
    "                      markerfacecolor = 'firebrick')\n",
    "meanlineprops = dict(linestyle='--', linewidth=2.5, color='purple')\n",
    "\n",
    "\n",
    "#imdb score vs color\n",
    "df = data[['color','imdb_score']]\n",
    "df.boxplot(by = 'color',showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#imdb score vs title word count\n",
    "#create a new column title_words as the word count of the title\n",
    "data['title_words'] = data['movie_title'].apply(lambda x: len(str(x).split(' ')))\n",
    "print(data.head(4))\n",
    "df = data[['title_words','imdb_score']]\n",
    "df.boxplot(by = 'title_words',showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#imdb score vs duration\n",
    "df = data[['duration','imdb_score']]\n",
    "df.boxplot(by='duration', showmeans=True, meanprops=meanpointprops, meanline=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#imdb score vs country\n",
    "df = data[['country','imdb_score']]\n",
    "df.boxplot(by='country', showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #imdb score vs language\n",
    "df = data[['language','imdb_score']]\n",
    "df.boxplot(by='language', showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#imdb score vs content rating\n",
    "df = data[['content_rating','imdb_score']]\n",
    "df.boxplot(by='content_rating', showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#imdb score vs face number in the poster\n",
    "df = data[['facenumber_in_poster','imdb_score']]\n",
    "df.boxplot(by='facenumber_in_poster', showmeans=True, meanprops=meanpointprops, figsize = [20,10])\n",
    "plt.show()\n",
    "data.plot.scatter('imdb_score','facenumber_in_poster')\n",
    "\n",
    "\n",
    "#imdb score vs title year\n",
    "df = data[['title_year','imdb_score']]\n",
    "df.boxplot(by='title_year', showmeans=True, figsize = [20,10])\n",
    "plt.show()\n",
    "\n",
    "#imdb score vs budget, gross and profit\n",
    "data.plot.scatter('imdb_score','budget')\n",
    "data.plot.scatter('imdb_score','gross')\n",
    "data['profit'] = data['gross'] - data['budget']\n",
    "data.plot.scatter('imdb_score','profit')\n",
    "\n",
    "\n",
    "#imdb score vs facebook popularity\n",
    "data.plot.scatter('imdb_score','movie_facebook_likes')\n",
    "data.plot.scatter('imdb_score','cast_total_facebook_likes')\n",
    "data.plot.scatter('imdb_score','director_facebook_likes')\n",
    "data.plot.scatter('imdb_score','actor_1_facebook_likes')\n",
    "data.plot.scatter('imdb_score','actor_2_facebook_likes')\n",
    "data.plot.scatter('imdb_score','actor_3_facebook_likes')\n",
    "# # plt.show()\n",
    "#\n",
    "#\n",
    "#imdb score vs user reviews and critic reviews\n",
    "data.plot.scatter('imdb_score','num_user_for_reviews')\n",
    "data.plot.scatter('imdb_score','num_critic_for_reviews')\n",
    "# # plt.show()\n",
    "#\n",
    "#voted users vs user reviews\n",
    "data.plot.scatter('num_user_for_reviews','num_voted_users')\n",
    "\n",
    "\n",
    "#correlation analysis\n",
    "import seaborn\n",
    "seaborn.heatmap(data.corr(), annot=True)\n",
    "\n",
    "#dropping 'cast_total_facebook_likes' as 'cast_total_facebook_likes' and'actor_1_facebook_likes' are highly correlated\n",
    "data = data.drop('cast_total_facebook_likes', axis=1)\n",
    "#dropping 'num_user_for_reviews' as 'num_user_for_reviews'and 'num_voted_users' are highly correlated\n",
    "data = data.drop('num_user_for_reviews', axis=1)\n",
    "\n",
    "# seaborn.heatmap(data.corr(), annot=True)\n",
    "\n",
    "# Summary:\n",
    "# Distribution of IMDB score is left-skewed. Mean is lower than median. There are some movies really bad.\n",
    "# There are much more color movies than black movies. Black movies have higher IMDB scores comparing to color movies.\n",
    "# Most of the movie titles contain fewer than 7 words.\n",
    "# Long movies tend to have high rating. Some really short movies also have higher rating.\n",
    "# Most of the movie posters contain fewer than 5 faces.\n",
    "# US and UK produced the greatest numbers of movies.\n",
    "# Movies in recent years have lower and lower IMDB mean score.\n",
    "# cast_total_facebook_likes and actor_1_facebook_likes are correlated.\n",
    "# num_user_for_reviews and num_voted_users are correlated.\n",
    "\n",
    "\n",
    "\n",
    "## Model Development and Evaluation\n",
    "\n",
    "#select variables\n",
    "data['color'] = data['color'].astype('category')\n",
    "data['language'] = data['language'].astype('category')\n",
    "data['country'] = data['country'].astype('category')\n",
    "data['content_rating'] = data['content_rating'].astype('category')\n",
    "# data.info()\n",
    "\n",
    "\n",
    "# columns and training/test sets preparation\n",
    "feature_cols = ['color','num_critic_for_reviews','duration','director_facebook_likes',\n",
    "                    'actor_3_facebook_likes','actor_1_facebook_likes','gross','num_voted_users',\n",
    "                    'facenumber_in_poster','language','country','content_rating','budget','profit',\n",
    "                    'title_year','actor_2_facebook_likes','aspect_ratio','movie_facebook_likes']\n",
    "\n",
    "numeric_cols = ['num_critic_for_reviews','duration','director_facebook_likes',\n",
    "                    'actor_3_facebook_likes','actor_1_facebook_likes','gross',\n",
    "                    'num_voted_users','facenumber_in_poster','budget','profit',\n",
    "                    'title_year','actor_2_facebook_likes','aspect_ratio','movie_facebook_likes']\n",
    "cat_cols = ['color','language','country','content_rating']\n",
    "\n",
    "\n",
    "X = data.loc[:, numeric_cols]\n",
    "y = data['imdb_score']\n",
    "X = X.as_matrix().astype(np.float)\n",
    "y = y.as_matrix().astype(np.float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=43)\n",
    "\n",
    "#Linear regression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print('Coefficients: ', lm.coef_)\n",
    "print('Intercept: ', lm.intercept_)\n",
    "\n",
    "y_pred = lm.predict(X_test)\n",
    "print(\"Mean squared error of linear regression: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score of linear regression: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "\n",
    "axes.scatter(y_test, y_pred, color='red', alpha=0.5)\n",
    "axes.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', lw=1)\n",
    "axes.set_xlabel('Actual')\n",
    "axes.set_ylabel('Predicted')\n",
    "\n",
    "\n",
    "#conclusion: linear regression with the numeric variables is not a good model.\n",
    "\n",
    "#Keras regression\n",
    "data_k = data[['num_critic_for_reviews','duration','director_facebook_likes',\n",
    "                    'actor_3_facebook_likes','actor_1_facebook_likes','gross','num_voted_users',\n",
    "                    'facenumber_in_poster','budget','profit','title_year',\n",
    "                    'actor_2_facebook_likes','aspect_ratio','movie_facebook_likes','imdb_score']]\n",
    "X = data_k.iloc[:, 0:14].values\n",
    "Y = data_k.iloc[:, 14:15].values\n",
    "\n",
    "X.shape\n",
    "Y.shape\n",
    "\n",
    "#define base model\n",
    "def baseline_model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    # model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "#evaluate base model\n",
    "np.random.seed(42)\n",
    "#evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=10, batch_size=50, verbose=1)\n",
    "#sing 10-fold cross validation to evaluate the model\n",
    "kfold = KFold(n_splits=10, random_state=42)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results of keras regression: %.2f (std %.2f) MAE\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "#define larger model: adding more hidden layers to the base model\n",
    "def larger_model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(9, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(7, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#evaluate larger model\n",
    "np.random.seed(42)\n",
    "estimator = KerasRegressor(build_fn=larger_model, nb_epoch=10, batch_size=50, verbose=1)\n",
    "kfold = KFold(n_splits=10, random_state=42)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Keras results with more hidden layers: %.2f (std %.2f) MAE\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "#define wider model, nearly doubling the number of neurons in two hidden layers\n",
    "def wider_model(learn_rate=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "#evaluate wider model\n",
    "np.random.seed(42)\n",
    "estimator = KerasRegressor(build_fn=wider_model, nb_epoch=10, batch_size=50, verbose=1)\n",
    "kfold = KFold(n_splits=10, random_state=42)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Keras results with more neurons: %.2f (std %.2f) MAE\" % (results.mean(), results.std()))\n",
    "\n",
    "# conclusion:\n",
    "# Results of Keras regression: mean -6.44 (std 0.11) MAE\n",
    "# Keras results with more hidden layers: -5.67 (std 1.05) MAE\n",
    "# Keras results with more neurons: -6.44 (std 0.11) MAE\n",
    "# Model with more number of hidden layers is performing better than the model having more number of neurons.\n",
    "\n",
    "\n",
    "#Tensorflow wide & deep learning\n",
    "\n",
    "color = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'color', ['Black and White', 'Color'])\n",
    "language = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'language', hash_bucket_size=1000)\n",
    "content_rating = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'content_rating', ['Approved', 'G', 'GP', 'M', 'NC-17', 'Not Rated', 'PG', 'PG-13',\n",
    "              'Passed', 'R', 'TV-14', 'TV-G', 'TV-PG', 'Unrated', 'X'])\n",
    "country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'country', hash_bucket_size=1000)\n",
    "\n",
    "\n",
    "title_year = tf.feature_column.numeric_column('title_year')\n",
    "duration = tf.feature_column.numeric_column('duration')\n",
    "gross = tf.feature_column.numeric_column('gross')\n",
    "budget = tf.feature_column.numeric_column('budget')\n",
    "profit = tf.feature_column.numeric_column('profit')\n",
    "aspect_ratio = tf.feature_column.numeric_column('aspect_ratio')\n",
    "facenumber_in_poster = tf.feature_column.numeric_column('facenumber_in_poster')\n",
    "movie_facebook_likes = tf.feature_column.numeric_column('movie_facebook_likes')\n",
    "director_facebook_likes = tf.feature_column.numeric_column('director_facebook_likes')\n",
    "actor_1_facebook_likes = tf.feature_column.numeric_column('actor_1_facebook_likes')\n",
    "actor_2_facebook_likes = tf.feature_column.numeric_column('actor_2_facebook_likes')\n",
    "actor_3_facebook_likes = tf.feature_column.numeric_column('actor_3_facebook_likes')\n",
    "num_critic_for_reviews = tf.feature_column.numeric_column('num_critic_for_reviews')\n",
    "num_voted_users = tf.feature_column.numeric_column('num_voted_users')\n",
    "\n",
    "\n",
    "base_columns = [\n",
    "    title_year, duration, gross, budget, profit, aspect_ratio, facenumber_in_poster, movie_facebook_likes,\n",
    "    director_facebook_likes, actor_1_facebook_likes, actor_2_facebook_likes, actor_3_facebook_likes,\n",
    "    num_critic_for_reviews, num_voted_users, color, country, language, content_rating,\n",
    "]\n",
    "\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "        ['country', 'language'], hash_bucket_size=1000),\n",
    "]\n",
    "\n",
    "deep_columns = [\n",
    "    num_critic_for_reviews,\n",
    "    duration,\n",
    "    director_facebook_likes,\n",
    "    actor_1_facebook_likes,\n",
    "    actor_2_facebook_likes,\n",
    "    actor_3_facebook_likes,\n",
    "    movie_facebook_likes,\n",
    "    gross,\n",
    "    budget,\n",
    "    profit,\n",
    "    num_voted_users,\n",
    "    facenumber_in_poster,\n",
    "    title_year,\n",
    "    aspect_ratio,\n",
    "    tf.feature_column.indicator_column(color),\n",
    "    tf.feature_column.indicator_column(country),\n",
    "    tf.feature_column.indicator_column(language),\n",
    "    tf.feature_column.embedding_column(content_rating, dimension=14),\n",
    "]\n",
    "\n",
    "\n",
    "data_t = data[['color','num_critic_for_reviews','duration','director_facebook_likes',\n",
    "                    'actor_3_facebook_likes','actor_1_facebook_likes','gross','num_voted_users',\n",
    "                    'facenumber_in_poster','language','country','content_rating','budget','profit',\n",
    "                    'title_year','actor_2_facebook_likes','aspect_ratio','movie_facebook_likes','imdb_score']]\n",
    "\n",
    "train, test = train_test_split(data_t, test_size=0.2)\n",
    "\n",
    "\n",
    "def input_fn(df, train= True):\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in numeric_cols}\n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices=[[i, 0] for i in range(df[k].size)],\n",
    "        values=df[k].values,\n",
    "        dense_shape=[df[k].size, 1])\n",
    "                      for k in cat_cols}\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_columns = continuous_cols.copy()\n",
    "    feature_columns.update(categorical_cols)\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    y = tf.constant(df['imdb_score'].values)\n",
    "    # Returns the feature columns and the label.\n",
    "    return feature_columns, y\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(test, train = False)\n",
    "\n",
    "\n",
    "estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "        model_dir='./tmp/model',\n",
    "        linear_feature_columns=base_columns + crossed_columns,\n",
    "        linear_optimizer=tf.train.FtrlOptimizer(\n",
    "            learning_rate=1e-8,\n",
    "            l1_regularization_strength=0.001,\n",
    "            l2_regularization_strength=0.001),\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=[1000, 500, 100],\n",
    "        dnn_optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "            learning_rate=1e-8,\n",
    "            l1_regularization_strength=0.001,\n",
    "            l2_regularization_strength=0.001))\n",
    "\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=50)\n",
    "print(estimator.predict(input_fn=lambda: input_fn(test)))\n",
    "results = estimator.evaluate(input_fn=eval_input_fn, steps=10)\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))\n",
    "\n",
    "predict = estimator.predict(input_fn=eval_input_fn)\n",
    "out = list(zip(list(data['movie_title']),list(results)))\n",
    "cols = ['movie_title', 'imdb_score']\n",
    "df_out = pd.DataFrame(out, columns=cols)\n",
    "\n",
    "df_out.to_csv(path_or_buf='./tmp/pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}